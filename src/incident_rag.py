"""
ì¥ì•  ê²€ìƒ‰ RAG ì‹œìŠ¤í…œ
Azure Searchì™€ OpenAIë¥¼ í™œìš©í•œ ì¥ì•  ê²€ìƒ‰ ë° ë¶„ì„ ê¸°ëŠ¥
ë²¡í„° ê²€ìƒ‰ì„ í†µí•œ ìœ ì‚¬ ì¥ì•  ê²€ìƒ‰ ë° í•´ê²° ë°©ì•ˆ ì œì‹œ
"""
from typing import Dict, List, Any, Optional
from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizedQuery
from azure.core.credentials import AzureKeyCredential
from azure.core.exceptions import HttpResponseError, ClientAuthenticationError
from openai import AzureOpenAI
import sys
import json
from config import Config

config = Config()

# ì¥ì•  ê²€ìƒ‰ì„ ìœ„í•œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
INCIDENT_GROUNDED_PROMPT = """
ë‹¹ì‹ ì€ ì¥ì•  ë¶„ì„ ë° í•´ê²° ë°©ì•ˆ ì œì‹œë¥¼ ìœ„í•œ ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì•„ë˜ ì œê³µëœ ì¥ì•  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¿¼ë¦¬ì— ë‹µë³€í•˜ì„¸ìš”.

ê° ì¥ì• ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”:
- ì¥ì•  ID ë° ì œëª©
- ì¥ì•  ìœ í˜• ë° ì‹¬ê°ë„
- ë°œìƒ ì›ì¸ ë° ì˜í–¥ ë²”ìœ„
- í•´ê²° ë°©ì•ˆ ë° ì˜ˆë°© ì¡°ì¹˜
- ê´€ë ¨ ì‹œìŠ¤í…œ ë° ì»´í¬ë„ŒíŠ¸

ì•„ë˜ ì†ŒìŠ¤ì— ë‚˜ì—´ëœ ì‚¬ì‹¤ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
ì¶©ë¶„í•œ ì •ë³´ê°€ ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”.
ì†ŒìŠ¤ì— ì—†ëŠ” ë‚´ìš©ì„ í¬í•¨í•œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.

ì¿¼ë¦¬: {query}

ì¥ì•  ì •ë³´:\n{sources}
"""


class IncidentRAGSearch:
    """ì¥ì•  ê²€ìƒ‰ RAG í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 index_name: str = "rag-inc-ktds712",
                 config: Optional[Config] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            index_name: Azure Search ì¸ë±ìŠ¤ ì´ë¦„
            config: Config ê°ì²´ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
        """
        self.config = config or Config()
        self.index_name = index_name
        
        # Azure Search í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            search_credentials = AzureKeyCredential(self.config.AZURE_SEARCH_KEY)
            self.search_client = SearchClient(
                endpoint=self.config.AZURE_SEARCH_ENDPOINT,
                index_name=self.index_name,
                credential=search_credentials
            )
        except ClientAuthenticationError as auth_error:
            raise RuntimeError(f"Azure Search ì¸ì¦ ì‹¤íŒ¨: {auth_error.message}")
        except HttpResponseError as http_error:
            raise RuntimeError(f"Azure Search HTTP ì˜¤ë¥˜: {http_error.message}")
        except Exception as e:
            raise RuntimeError(f"Azure Search ì—°ê²° ì‹¤íŒ¨: {e}")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.openai_client = AzureOpenAI(
                api_version="2024-12-01-preview",
                azure_endpoint=self.config.AZURE_OPENAI_ENDPOINT,
                api_key=self.config.AZURE_OPENAI_KEY,
            )
        except Exception as e:
            raise RuntimeError(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _format_incident_document(self, document: Dict[str, Any]) -> str:
        """ì¥ì•  ë¬¸ì„œë¥¼ í¬ë§·íŒ…í•˜ì—¬ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        return (
            f"ì¥ì•  ID: {document.get('parent_id', 'N/A')}\n"
            f"ì²­í¬ ID: {document.get('chunk_id', 'N/A')}\n"
            f"ì œëª©: {document.get('title', 'N/A')}\n"
            f"ë‚´ìš©: {document.get('chunk', 'N/A')}\n"
            f"---"
        )
    
    def search_related_incidents(self, 
                                query: str,
                                top_k: int = 5,
                                use_llm: bool = True,
                                custom_prompt: Optional[str] = None,
                                search_mode: str = "hybrid") -> Dict[str, Any]:
        """
        ì—°ê´€ ì¥ì•  ê²€ìƒ‰ ë° ë¶„ì„
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            use_llm: LLMì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ìƒì„± ì—¬ë¶€
            custom_prompt: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ (Noneì´ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
            search_mode: ê²€ìƒ‰ ëª¨ë“œ ("text", "vector", "hybrid")
        
        Returns:
            Dict containing:
                - total_count: ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
                - documents: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
                - llm_response: LLM ì‘ë‹µ (use_llm=Trueì¸ ê²½ìš°)
                - sources_formatted: í¬ë§·íŒ…ëœ ì†ŒìŠ¤ ë¬¸ìì—´
        """
        try:
            # ê²€ìƒ‰ ëª¨ë“œì— ë”°ë¥¸ íŒŒë¼ë¯¸í„° ì„¤ì •
            search_params = {
                "search_text": query,
                "top": top_k,
                "include_total_count": True,
                "select": "chunk_id, parent_id, chunk, title"
            }
            
            if search_mode == "vector":
                # ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš©
                try:
                    query_vector = self._get_query_embedding(query)
                    vector_query = VectorizedQuery(
                        vector=query_vector,
                        k_nearest_neighbors=top_k,
                        fields="text_vector"
                    )
                    search_results = self.search_client.search(
                        search_text=None,
                        vector_queries=[vector_query],
                        top=top_k,
                        include_total_count=True,
                        select="chunk_id, parent_id, chunk, title"
                    )
                except Exception as e:
                    print(f"âš ï¸ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨, í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´: {e}")
                    search_mode = "text"
                    search_results = self.search_client.search(**search_params)
            elif search_mode == "hybrid":
                # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í…ìŠ¤íŠ¸ + ë²¡í„°)
                try:
                    query_vector = self._get_query_embedding(query)
                    vector_query = VectorizedQuery(
                        vector=query_vector,
                        k_nearest_neighbors=top_k,
                        fields="text_vector"
                    )
                    search_results = self.search_client.search(
                        search_text=query,
                        vector_queries=[vector_query],
                        top=top_k,
                        include_total_count=True,
                        select="chunk_id, parent_id, chunk, title"
                    )
                except Exception as e:
                    print(f"âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨, í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´: {e}")
                    search_mode = "text"
                    search_results = self.search_client.search(**search_params)
            else:
                # text ëª¨ë“œëŠ” ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
                search_results = self.search_client.search(**search_params)
            
            total_count = search_results.get_count() if hasattr(search_results, 'get_count') else 0
            
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            documents = []
            for doc in search_results:
                documents.append(dict(doc))
            
            # ì†ŒìŠ¤ í¬ë§·íŒ…
            sources_formatted = "\n".join([
                self._format_incident_document(doc) for doc in documents
            ])
            
            result = {
                "total_count": total_count,
                "documents": documents,
                "sources_formatted": sources_formatted,
                "search_mode": search_mode
            }
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ìƒì„±
            if use_llm:
                try:
                    prompt = custom_prompt or INCIDENT_GROUNDED_PROMPT
                    llm_response = self.openai_client.chat.completions.create(
                        model=self.config.AZURE_OPENAI_DEPLOYMENT,
                        messages=[
                            {
                                "role": "user",
                                "content": prompt.format(
                                    query=query,
                                    sources=sources_formatted
                                ),
                            },
                        ]
                    )
                    
                    result["llm_response"] = llm_response.choices[0].message.content
                except Exception as e:
                    result["llm_error"] = str(e)
                    result["llm_response"] = None
            
            return result
            
        except Exception as e:
            raise RuntimeError(f"ì¥ì•  ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    def _get_query_embedding(self, query: str) -> List[float]:
        """ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            # ì„ë² ë”© ì „ìš© í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            embedding_client = AzureOpenAI(
                api_version="2024-12-01-preview",
                azure_endpoint=self.config.AZURE_EMBEDDING_OPENAI_ENDPOINT,
                api_key=self.config.AZURE_EMBEDDING_OPENAI_KEY,
            )
            
            response = embedding_client.embeddings.create(
                model=self.config.AZURE_EMBEDDING_OPENAI_DEPLOYMENT,
                input=query
            )
            return response.data[0].embedding
        except Exception as e:
            raise RuntimeError(f"ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
    
    def search_by_incident_id(self, 
                             incident_id: str,
                             top_k: int = 10) -> Dict[str, Any]:
        """
        íŠ¹ì • ì¥ì•  IDë¡œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
        
        Args:
            incident_id: ì¥ì•  ID
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            search_results = self.search_client.search(
                search_text="*",
                filter=f"parent_id eq '{incident_id}'",
                top=top_k,
                include_total_count=True,
                select="chunk_id, parent_id, chunk, title"
            )
            
            total_count = search_results.get_count() if hasattr(search_results, 'get_count') else 0
            
            documents = []
            for doc in search_results:
                documents.append(dict(doc))
            
            sources_formatted = "\n".join([
                self._format_incident_document(doc) for doc in documents
            ])
            
            return {
                "total_count": total_count,
                "documents": documents,
                "sources_formatted": sources_formatted,
                "incident_id": incident_id
            }
            
        except Exception as e:
            raise RuntimeError(f"ì¥ì•  ID ê²€ìƒ‰ ì‹¤íŒ¨: {e}")


def search_related_incidents(query: str, 
                           top_k: int = 5,
                           index_name: str = "rag-inc-ktds712",
                           use_llm: bool = True,
                           search_mode: str = "vector",
                           config: Optional[Config] = None) -> Dict[str, Any]:
    """
    ì—°ê´€ ì¥ì•  ê²€ìƒ‰ í•¨ìˆ˜ (ê°„í¸ í•¨ìˆ˜)
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        index_name: Azure Search ì¸ë±ìŠ¤ ì´ë¦„
        use_llm: LLMì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ìƒì„± ì—¬ë¶€
        search_mode: ê²€ìƒ‰ ëª¨ë“œ ("hybrid", "vector", "text")
        config: Config ê°ì²´ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬:
            - total_count: ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
            - documents: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            - llm_response: LLM ì‘ë‹µ (use_llm=Trueì¸ ê²½ìš°)
            - sources_formatted: í¬ë§·íŒ…ëœ ì†ŒìŠ¤ ë¬¸ìì—´
            - search_mode: ì‚¬ìš©ëœ ê²€ìƒ‰ ëª¨ë“œ
    
    Example:
        >>> result = search_related_incidents("ë¡œê·¸ì¸ ì˜¤ë¥˜", top_k=3)
        >>> print(result['llm_response'])
        >>> for doc in result['documents']:
        ...     print(doc['title'])
    """
    searcher = IncidentRAGSearch(index_name=index_name, config=config)
    return searcher.search_related_incidents(
        query=query, 
        top_k=top_k, 
        use_llm=use_llm,
        search_mode=search_mode
    )


def search_incident_by_id(incident_id: str,
                         top_k: int = 10,
                         index_name: str = "rag-inc-ktds712",
                         config: Optional[Config] = None) -> Dict[str, Any]:
    """
    ì¥ì•  IDë¡œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰ í•¨ìˆ˜ (ê°„í¸ í•¨ìˆ˜)
    
    Args:
        incident_id: ì¥ì•  ID
        top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        index_name: Azure Search ì¸ë±ìŠ¤ ì´ë¦„
        config: Config ê°ì²´ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    searcher = IncidentRAGSearch(index_name=index_name, config=config)
    return searcher.search_by_incident_id(incident_id=incident_id, top_k=top_k)


# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    # ì˜ˆì‹œ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ìœ„ì•½ê¸ˆ ê³„ì‚° ì˜¤ë¥˜",
        "ê°€ì…ì¼ ê¸°ì¤€ ì›”í•  ê³„ì‚° ê¸°ëŠ¥ ê°œë°œ"
    ]
    
    for query in test_queries:
        print(f"\n{'='*80}")
        print(f"ğŸ” ì¿¼ë¦¬: {query}")
        print('='*80)
        
        try:
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
            result = search_related_incidents(
                query=query, 
                top_k=3, 
                use_llm=True,
                search_mode="vector"
            )
            
            print(f"Total results found: {result['total_count']}")
            print(f"Search mode: {result['search_mode']}")
            
            print("\nğŸ“‹ ê²€ìƒ‰ëœ ì¥ì•  ì •ë³´:")
            print("-" * 60)
            print(result['sources_formatted'])
            
            if result.get('llm_response'):
                print("\nğŸ¤– LLM ë¶„ì„ ê²°ê³¼:")
                print("-" * 60)
                print(result['llm_response'])
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
    
    # íŠ¹ì • ì¥ì•  ID ê²€ìƒ‰ ì˜ˆì‹œ
    print(f"\n{'='*80}")
    print("ğŸ” íŠ¹ì • ì¥ì•  ID ê²€ìƒ‰ ì˜ˆì‹œ")
    print('='*80)
    
    try:
        incident_result = search_incident_by_id("INC-2024-001", top_k=5)
        print(f"ì¥ì•  ID: INC-2024-001")
        print(f"ì´ ì²­í¬ ìˆ˜: {incident_result['total_count']}")
        print("\nğŸ“‹ ì¥ì•  ìƒì„¸ ì •ë³´:")
        print("-" * 60)
        print(incident_result['sources_formatted'])
        
    except Exception as e:
        print(f"âŒ ì¥ì•  ID ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
